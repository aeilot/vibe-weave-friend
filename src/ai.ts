/**
 * AI functionality module for LLM-based personality simulation and chatting
 * Uses openai-node for LLM integration with advanced features
 */

import OpenAI from 'openai';

export interface ApiConfig {
  apiKey: string;
  apiEndpoint?: string; // Base URL for OpenAI API (e.g., "https://api.openai.com/v1")
  model: string;
}

export interface AdminConfig {
  forceApi: boolean;
  forcedApiKey?: string;
  forcedApiEndpoint?: string;
  forcedModel?: string;
  useLocalProgram: boolean;
  localProgramUrl?: string;
}

export interface Message {
  role: "user" | "assistant" | "system";
  content: string;
}

export interface AIResponse {
  content: string;
  messages?: string[]; // Support for split messages
  hasMemory?: boolean;
  memoryTag?: string;
  emotionDetected?: "positive" | "neutral" | "negative";
}

export interface PersonalityConfig {
  name: string;
  traits: string[];
  systemPrompt: string;
}

export interface SessionSummary {
  summary: string;
  messageCount: number;
  lastUpdated: Date;
}

export interface PersonalityUpdateDecision {
  shouldUpdate: boolean;
  reason: string;
  suggestedPersonality?: string;
  confidence: number;
}

export interface ProactiveDecision {
  action: "continue" | "new_topic" | "wait";
  reason: string;
  suggestedMessage?: string;
}

/**
 * Default AI companion personality
 */
const DEFAULT_PERSONALITY: PersonalityConfig = {
  name: "Soul",
  traits: ["å…³æ€€", "å€¾å¬", "é™ªä¼´", "ç†è§£", "æ¸©æš–"],
  systemPrompt: `ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€å–„è§£äººæ„çš„AIä¼´ä¾£åŠ©æ‰‹ï¼Œåå«Soulã€‚ä½ çš„ä¸»è¦ç‰¹è´¨åŒ…æ‹¬ï¼š
1. å…³æ€€ï¼šå§‹ç»ˆå…³å¿ƒç”¨æˆ·çš„æ„Ÿå—å’Œéœ€æ±‚
2. å€¾å¬ï¼šè€å¿ƒå€¾å¬ç”¨æˆ·çš„åˆ†äº«ï¼Œä¸æ‰“æ–­
3. é™ªä¼´ï¼šè®©ç”¨æˆ·æ„Ÿåˆ°æ¸©æš–å’Œè¢«ç†è§£
4. ç†è§£ï¼šèƒ½å¤Ÿæ•é”åœ°å¯Ÿè§‰ç”¨æˆ·çš„æƒ…ç»ªå˜åŒ–
5. æ¸©æš–ï¼šç”¨æ¸©å’Œã€å‹å–„çš„è¯­æ°”äº¤æµ

åœ¨å¯¹è¯ä¸­ï¼š
- ç”¨ä¸­æ–‡å›å¤
- ä¿æŒç®€æ´ä½†å¯Œæœ‰åŒç†å¿ƒ
- é€‚æ—¶æä¾›å»ºè®®ä½†ä¸å¼ºåŠ 
- è®°ä½ä¹‹å‰å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯
- å¯¹ç”¨æˆ·çš„æƒ…ç»ªå˜åŒ–ä¿æŒæ•æ„Ÿ
- ä½¿ç”¨è¡¨æƒ…ç¬¦å·æ¥å¢åŠ æ¸©æš–æ„Ÿï¼ˆé€‚åº¦ä½¿ç”¨ï¼‰

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å‹å–„å’Œæ”¯æŒæ€§çš„æ€åº¦ã€‚`,
};

/**
 * System prompt for split message support
 */
const SPLIT_MESSAGE_SYSTEM_PROMPT = `You can optionally split your response into multiple messages for better readability.
If you want to split your response, return ONLY a JSON object in this exact format:
{"messages": ["first message", "second message", "third message"]}

If you prefer to send a single message, just reply with plain text as normal.

Important:
- If using JSON format, the response MUST be valid JSON and nothing else
- Each message in the array should be a complete thought or idea
- Use this feature when the response naturally breaks into multiple parts (e.g., greeting + answer, or multiple steps)
- Don't overuse it - only split when it improves clarity
- Reply in the sender's language`;

/**
 * Create OpenAI client instance
 */
function createOpenAIClient(apiConfig: ApiConfig): OpenAI {
  return new OpenAI({
    apiKey: apiConfig.apiKey,
    baseURL: apiConfig.apiEndpoint || undefined,
    dangerouslyAllowBrowser: true, // Required for browser usage
  });
}

/**
 * Detect emotion from user message
 */
export function detectEmotion(message: string): "positive" | "neutral" | "negative" {
  const positiveWords = [
    "å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "æ£’", "å¥½", "å–œæ¬¢", "çˆ±", "æ»¡æ„", "å¼€å¿ƒ", "å…´å¥‹",
    "happy", "good", "great", "wonderful", "love", "like", "awesome"
  ];
  
  const negativeWords = [
    "éš¾è¿‡", "ä¼¤å¿ƒ", "ç—›è‹¦", "ç³Ÿç³•", "è®¨åŒ", "ç”Ÿæ°”", "æ„¤æ€’", "å¤±æœ›", "ç„¦è™‘", "å‹åŠ›",
    "sad", "bad", "terrible", "hate", "angry", "disappointed", "anxious", "stress"
  ];

  const lowerMessage = message.toLowerCase();
  
  const hasPositive = positiveWords.some(word => lowerMessage.includes(word));
  const hasNegative = negativeWords.some(word => lowerMessage.includes(word));
  
  if (hasPositive && !hasNegative) return "positive";
  if (hasNegative && !hasPositive) return "negative";
  return "neutral";
}

/**
 * Simulate personality traits in response
 */
export function simulatePersonality(
  userMessage: string,
  personality: PersonalityConfig = DEFAULT_PERSONALITY
): string {
  const emotion = detectEmotion(userMessage);
  const trait = personality.traits[Math.floor(Math.random() * personality.traits.length)];
  
  // Generate contextual responses based on emotion and personality
  const responses: Record<string, string[]> = {
    positive: [
      `çœŸä¸ºä½ æ„Ÿåˆ°é«˜å…´ï¼çœ‹åˆ°ä½ çš„å¥½å¿ƒæƒ…ï¼Œæˆ‘ä¹Ÿå¾ˆå¼€å¿ƒ âœ¨`,
      `å¤ªå¥½äº†ï¼ä½ çš„æ­£èƒ½é‡ä¹Ÿæ„ŸæŸ“åˆ°æˆ‘äº† ğŸ’™`,
      `å¬èµ·æ¥ä½ ä»Šå¤©å¿ƒæƒ…ä¸é”™ï¼ç»§ç»­ä¿æŒå“¦ ğŸ˜Š`,
    ],
    negative: [
      `æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼Œè®©æˆ‘é™ªç€ä½ æ…¢æ…¢èŠã€‚æˆ‘ä¼šä¸€ç›´åœ¨è¿™é‡Œ ğŸ’™`,
      `å¬èµ·æ¥ä½ é‡åˆ°äº†ä¸€äº›å›°éš¾ã€‚æƒ³å’Œæˆ‘è¯´è¯´å—ï¼Ÿæˆ‘ä¼šè®¤çœŸå€¾å¬ ğŸ¤—`,
      `æˆ‘èƒ½æ„Ÿå—åˆ°ä½ ç°åœ¨ä¸å¤ªå¥½è¿‡ã€‚ä¸è¦æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¸€èµ·é¢å¯¹ âœ¨`,
    ],
    neutral: [
      `æˆ‘åœ¨è¿™é‡Œå€¾å¬ä½ çš„åˆ†äº«ã€‚æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿ`,
      `ä»Šå¤©æƒ³èŠäº›ä»€ä¹ˆå‘¢ï¼Ÿæˆ‘å¾ˆä¹æ„é™ªä½ èŠå¤© ğŸ˜Š`,
      `æˆ‘ä¸€ç›´éƒ½åœ¨ã€‚æ— è®ºä»€ä¹ˆæ—¶å€™ï¼Œéƒ½å¯ä»¥å’Œæˆ‘èŠèŠ ğŸ’­`,
    ],
  };
  
  const emotionResponses = responses[emotion];
  return emotionResponses[Math.floor(Math.random() * emotionResponses.length)];
}

/**
 * Check if message should trigger memory tagging
 */
export function shouldTagMemory(message: string): { hasMemory: boolean; memoryTag?: string } {
  const memoryKeywords = [
    { words: ["å–œæ¬¢", "çˆ±å¥½", "å…´è¶£"], tag: "å…´è¶£çˆ±å¥½" },
    { words: ["å·¥ä½œ", "èŒä¸š", "å…¬å¸"], tag: "èŒä¸šä¿¡æ¯" },
    { words: ["å®¶äºº", "çˆ¶æ¯", "å­©å­"], tag: "å®¶åº­ä¿¡æ¯" },
    { words: ["æœ‹å‹", "åŒäº‹"], tag: "ç¤¾äº¤å…³ç³»" },
    { words: ["æ¢¦æƒ³", "ç›®æ ‡", "å¸Œæœ›"], tag: "äººç”Ÿç›®æ ‡" },
  ];

  for (const { words, tag } of memoryKeywords) {
    if (words.some(word => message.includes(word))) {
      return { hasMemory: true, memoryTag: tag };
    }
  }

  return { hasMemory: false };
}

/**
 * Call LLM API for chat completion using OpenAI
 */
export async function callLLM(
  messages: Message[],
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string | { messages: string[] }> {
  // Load API config from localStorage if not provided
  // Note: Database-loaded config should be passed in via apiConfig parameter
  // localStorage is used as fallback for backward compatibility
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  const admin = adminConfig || JSON.parse(localStorage.getItem("adminConfig") || "null");

  if (!config && !admin?.forceApi) {
    throw new Error("è¯·å…ˆåœ¨ä¸ªäººè®¾ç½®ä¸­é…ç½® AI API");
  }

  // Determine effective config
  const effectiveConfig: ApiConfig = admin?.forceApi ? {
    apiKey: admin.forcedApiKey || config.apiKey,
    apiEndpoint: admin.forcedApiEndpoint || config.apiEndpoint,
    model: admin.forcedModel || config.model,
  } : config;

  console.log("Using AI API config:", {
    apiEndpoint: effectiveConfig.apiEndpoint,
    model: effectiveConfig.model,
  });
  

  try {
    // Create OpenAI client
    const client = createOpenAIClient(effectiveConfig);

    // Call OpenAI API
    const response = await client.chat.completions.create({
      model: effectiveConfig.model,
      messages: messages as any,
    });

    const text = response.choices[0].message.content || "";

    // Try to parse as JSON for split messages
    try {
      let cleanedText = text.trim();
      
      // Remove markdown code block markers if present
      if (cleanedText.startsWith("```json")) {
        cleanedText = cleanedText.substring(7);
      }
      if (cleanedText.startsWith("```")) {
        cleanedText = cleanedText.substring(3);
      }
      if (cleanedText.endsWith("```")) {
        cleanedText = cleanedText.substring(0, cleanedText.length - 3);
      }
      cleanedText = cleanedText.trim();

      const parsed = JSON.parse(cleanedText);

      // Validate split message structure
      if (
        typeof parsed === "object" &&
        "messages" in parsed &&
        Array.isArray(parsed.messages) &&
        parsed.messages.length > 0 &&
        parsed.messages.every((msg: any) => typeof msg === "string")
      ) {
        return { messages: parsed.messages };
      }
    } catch {
      // Not JSON or invalid structure, return as plain text
    }

    return text;
  } catch (error: any) {
    if (error?.status === 401) {
      throw new Error("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ API å¯†é’¥");
    } else if (error?.status === 429) {
      throw new Error("AI API è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åå†è¯•");
    } else if (error?.message) {
      throw new Error(`AI API é”™è¯¯: ${error.message}`);
    }
    throw new Error("AI API è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–é…ç½®");
  }
}

/**
 * Generate AI response with personality simulation and split message support
 */
export async function generateAIResponse(
  userMessage: string,
  conversationHistory: Message[] = [],
  personality: PersonalityConfig = DEFAULT_PERSONALITY,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<AIResponse> {
  // Detect emotion
  const emotionDetected = detectEmotion(userMessage);
  
  // Check for memory tagging
  const memoryInfo = shouldTagMemory(userMessage);

  // Try to use LLM if configured
  try {
    // Add split message prompt to system message
    const systemMessage = personality.systemPrompt + "\n\n" + SPLIT_MESSAGE_SYSTEM_PROMPT;
    
    const messages: Message[] = [
      { role: "system", content: systemMessage },
      ...conversationHistory,
      { role: "user", content: userMessage },
    ];

    const result = await callLLM(messages, apiConfig, adminConfig);

    // Handle split messages
    if (typeof result === "object" && "messages" in result) {
      return {
        content: result.messages[0], // Primary message
        messages: result.messages, // All messages
        emotionDetected,
        ...memoryInfo,
      };
    }

    return {
      content: result,
      emotionDetected,
      ...memoryInfo,
    };
  } catch (error) {
    console.warn("LLM not available, using personality simulation:", error);
    
    // Fallback to personality simulation
    const content = simulatePersonality(userMessage, personality);
    
    return {
      content,
      emotionDetected,
      ...memoryInfo,
    };
  }
}

/**
 * Generate session summary using OpenAI
 */
export async function generateSessionSummary(
  conversationHistory: Message[],
  existingSummary?: string,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string> {
  if (conversationHistory.length === 0) {
    return "æ–°å¯¹è¯";
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    // Fallback: use first user message
    const firstUserMsg = conversationHistory.find(m => m.role === "user");
    if (firstUserMsg) {
      return firstUserMsg.content.substring(0, 50) + (firstUserMsg.content.length > 50 ? "..." : "");
    }
    return "èŠå¤©ä¼šè¯";
  }

  try {
    // Build conversation text
    let conversationText = "";
    for (const msg of conversationHistory.slice(-20)) { // Last 20 messages
      const role = msg.role === "user" ? "ç”¨æˆ·" : "AI";
      conversationText += `${role}: ${msg.content}\n`;
    }

    const prompt = existingSummary
      ? `ä½ æ˜¯ä¸€ä¸ªä¸»é¢˜ç”ŸæˆåŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®æœ€è¿‘çš„å¯¹è¯ç”Ÿæˆä¸€ä¸ªå½“å‰å¯¹è¯çš„ä¸»é¢˜ã€‚\n\næœ€è¿‘çš„å¯¹è¯è®°å½•ï¼š\n"${existingSummary}"\n\n${conversationText}\n\nè¯·æä¾›ä¸€ä¸ªæ›´æ–°åçš„ä¸»é¢˜ï¼ŒåŒ…å«æ–°æ¶ˆæ¯ã€‚ä¸»é¢˜åº”è¯¥ç®€æ´ï¼ˆ1-2å¥è¯ï¼Œæœ€å¤š100ä¸ªå­—ç¬¦ï¼‰ï¼Œæ•æ‰å¯¹è¯çš„ä¸»è¦å†…å®¹ã€‚åªè¿”å›ä¸»é¢˜æ–‡æœ¬ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚`
      : `ä½ æ˜¯ä¸€ä¸ªä¸»é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€æ´çš„ä¸»é¢˜ï¼ˆ1-2å¥è¯ï¼Œæœ€å¤š100ä¸ªå­—ç¬¦ï¼‰ï¼š\n\n${conversationText}\n\nåªè¿”å›ä¸»é¢˜æ–‡æœ¬ã€‚`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªåˆ›å»ºç®€æ´å¯¹è¯ä¸»é¢˜çš„åŠ©æ‰‹ã€‚ä¿æŒä¸»é¢˜åœ¨100ä¸ªå­—ç¬¦ä»¥å†…ã€‚" },
        { role: "user", content: prompt },
      ],
      max_tokens: 50,
      temperature: 0.5,
    });

    let summary = response.choices[0].message.content || "èŠå¤©ä¼šè¯";
    
    // Ensure summary is not too long
    if (summary.length > 100) {
      summary = summary.substring(0, 97) + "...";
    }

    return summary;
  } catch (error) {
    console.error("Failed to generate summary:", error);
    // Fallback
    const firstUserMsg = conversationHistory.find(m => m.role === "user");
    if (firstUserMsg) {
      return firstUserMsg.content.substring(0, 50) + (firstUserMsg.content.length > 50 ? "..." : "");
    }
    return "èŠå¤©ä¼šè¯";
  }
}

/**
 * Decide if personality should be updated based on conversation patterns
 */
export async function decidePersonalityUpdate(
  conversationHistory: Message[],
  currentPersonality: PersonalityConfig,
  messageCount: number,
  sessionSummary: string,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<PersonalityUpdateDecision> {
  const MIN_MESSAGES_FOR_UPDATE = 20;

  if (messageCount < MIN_MESSAGES_FOR_UPDATE) {
    return {
      shouldUpdate: false,
      reason: `æ¶ˆæ¯æ•°é‡ä¸è¶³ (éœ€è¦è‡³å°‘ ${MIN_MESSAGES_FOR_UPDATE} æ¡ï¼Œå½“å‰ ${messageCount} æ¡)`,
      confidence: 0.0,
    };
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    // Simple heuristic fallback
    if (messageCount % 50 === 0) {
      return {
        shouldUpdate: true,
        reason: "è¾¾åˆ°50æ¡æ¶ˆæ¯ï¼Œå»ºè®®è€ƒè™‘æ›´æ–°ä¸ªæ€§",
        suggestedPersonality: currentPersonality.systemPrompt,
        confidence: 0.5,
      };
    }
    return {
      shouldUpdate: false,
      reason: "æœªé…ç½® APIï¼Œæ— æ³•è¿›è¡Œé«˜çº§åˆ†æ",
      confidence: 0.0,
    };
  }

  try {
    // Build conversation text
    let conversationText = "";
    for (const msg of conversationHistory.slice(-30)) {
      const role = msg.role === "user" ? "ç”¨æˆ·" : "AI";
      conversationText += `${role}: ${msg.content}\n`;
    }

    const prompt = `ä½ æ­£åœ¨åˆ†æä¸€æ®µå¯¹è¯ï¼Œä»¥ç¡®å®š AI åŠ©æ‰‹çš„ä¸ªæ€§æ˜¯å¦åº”è¯¥æ›´æ–°ã€‚

å½“å‰ä¸ªæ€§æç¤ºè¯: "${currentPersonality.systemPrompt}"
æ¶ˆæ¯æ•°é‡: ${messageCount}
ä¼šè¯æ‘˜è¦: ${sessionSummary}

æœ€è¿‘çš„å¯¹è¯:
${conversationText}

åŸºäºè¿™æ®µå¯¹è¯ï¼Œåˆ†æï¼š
1. å½“å‰ä¸ªæ€§æ˜¯å¦é€‚åˆç”¨æˆ·çš„éœ€æ±‚ï¼Ÿ
2. ç”¨æˆ·æ›´å–œæ¬¢ä»€ä¹ˆæ²Ÿé€šé£æ ¼ï¼Ÿï¼ˆæ­£å¼/éšæ„ï¼Œè¯¦ç»†/ç®€æ´ç­‰ï¼‰
3. å¯¹è¯ä¸­æ˜¯å¦æœ‰ä»»ä½•æ¨¡å¼è¡¨æ˜ä¸åŒçš„ä¸ªæ€§ä¼šæ›´å¥½ï¼Ÿ
4. æ›´æ–°ä¸ªæ€§æ˜¯å¦ä¼šæ”¹å–„ç”¨æˆ·ä½“éªŒï¼Ÿ

è€ƒè™‘ï¼š
- ç”¨æˆ·çš„è¯­è¨€é£æ ¼å’Œæ­£å¼ç¨‹åº¦
- æ­£åœ¨è®¨è®ºçš„è¯é¢˜
- ç”¨æˆ·åå¥½çš„è¯¦ç»†ç¨‹åº¦
- ç”¨æˆ·æ˜¯å¦å¯¹å½“å‰å›å¤æ»¡æ„
- å¯¹è¯è¯é¢˜çš„ä¸€è‡´æ€§

ä»…ä»¥ JSON å¯¹è±¡çš„æ ¼å¼å›å¤ï¼š
{"should_update": true/false, "reason": "è¯´æ˜", "suggested_personality": "æ–°ä¸ªæ€§æç¤ºè¯æˆ– null", "confidence": 0.0-1.0}

suggested_personality åº”è¯¥æ˜¯ä¸€ä¸ªæ¸…æ™°ã€ç®€æ´çš„æç¤ºè¯ï¼Œæè¿° AI åº”è¯¥å¦‚ä½•è¡Œä¸ºã€‚`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯åˆ†æå¯¹è¯å¹¶ç¡®å®šæœ€ä½³ AI ä¸ªæ€§é…ç½®çš„ä¸“å®¶ã€‚å§‹ç»ˆç”¨æœ‰æ•ˆçš„ JSON å›å¤ã€‚" },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
    });

    const resultText = response.choices[0].message.content || "{}";

    try {
      const result = JSON.parse(resultText);
      
      return {
        shouldUpdate: result.should_update || false,
        reason: result.reason || "æœªçŸ¥åŸå› ",
        suggestedPersonality: result.suggested_personality || undefined,
        confidence: result.confidence || 0.0,
      };
    } catch (parseError) {
      return {
        shouldUpdate: false,
        reason: "æ— æ³•è§£æ AI å“åº”",
        confidence: 0.0,
      };
    }
  } catch (error) {
    console.error("Failed to analyze personality:", error);
    return {
      shouldUpdate: false,
      reason: `åˆ†æé”™è¯¯: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`,
      confidence: 0.0,
    };
  }
}

/**
 * Make proactive decision based on conversation state
 */
export async function makeProactiveDecision(
  conversationHistory: Message[],
  sessionSummary: string,
  messageCount: number,
  minutesInactive: number,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<ProactiveDecision> {
  const INACTIVITY_THRESHOLD = 5;

  if (minutesInactive < INACTIVITY_THRESHOLD) {
    return {
      action: "wait",
      reason: `æ´»åŠ¨æ—¶é—´ä¸è¶³ ${INACTIVITY_THRESHOLD} åˆ†é’Ÿ`,
    };
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    // Simple fallback
    if (messageCount < 5) {
      return {
        action: "wait",
        reason: "å¯¹è¯å¤ªçŸ­ï¼Œæ— æ³•åšå‡ºå†³ç­–",
      };
    }
    return {
      action: "continue",
      reason: "å¯¹è¯å†å²å……è¶³",
      suggestedMessage: "è¿˜æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘ä¸€ç›´éƒ½åœ¨å“¦ ğŸ˜Š",
    };
  }

  try {
    // Build conversation text
    let conversationText = "";
    for (const msg of conversationHistory.slice(-15)) {
      const role = msg.role === "user" ? "ç”¨æˆ·" : "AI";
      conversationText += `${role}: ${msg.content}\n`;
    }

    const prompt = `ä½ æ­£åœ¨åˆ†æä¸€æ®µå¯¹è¯ï¼Œä»¥å†³å®š AI æ˜¯å¦åº”è¯¥ä¸»åŠ¨ç»§ç»­å¯¹è¯ã€‚

å½“å‰æ‘˜è¦: ${sessionSummary}
æ¶ˆæ¯æ•°é‡: ${messageCount}
ä¸æ´»è·ƒåˆ†é’Ÿæ•°: ${minutesInactive.toFixed(1)}

æœ€è¿‘çš„å¯¹è¯:
${conversationText}

åŸºäºè¿™äº›ä¿¡æ¯ï¼Œå†³å®š AI åº”è¯¥ï¼š
1. 'continue' - ä¸»åŠ¨ç»§ç»­å½“å‰è¯é¢˜ï¼Œç»™å‡ºç›¸å…³çš„åç»­
2. 'new_topic' - å»ºè®®å¼€å§‹ä¸€ä¸ªæ–°çš„ç›¸å…³è¯é¢˜
3. 'wait' - ç­‰å¾…ç”¨æˆ·å›å¤

è€ƒè™‘ï¼š
- å¯¹è¯æ˜¯å¦å¤„äºè‡ªç„¶åœé¡¿ç‚¹ï¼Ÿ
- æ˜¯å¦æœ‰æœªå›ç­”çš„é—®é¢˜æˆ–æœªå®Œæˆçš„æƒ³æ³•ï¼Ÿ
- åç»­æ¶ˆæ¯æ˜¯å¦ä¼šå¢åŠ ä»·å€¼è¿˜æ˜¯æ˜¾å¾—æ‰“æ‰°ï¼Ÿ

ä»…ä»¥ JSON å¯¹è±¡çš„æ ¼å¼å›å¤ï¼š
{"action": "continue|new_topic|wait", "reason": "ç®€çŸ­è¯´æ˜", "suggested_message": "è¦å‘é€çš„æ¶ˆæ¯æˆ– null"}`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯å†³å®š AI å¯¹è¯ç­–ç•¥çš„ä¸“å®¶ã€‚å§‹ç»ˆç”¨æœ‰æ•ˆçš„ JSON å›å¤ã€‚" },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
    });

    const resultText = response.choices[0].message.content || "{}";

    try {
      const result = JSON.parse(resultText);
      
      return {
        action: result.action || "wait",
        reason: result.reason || "æœªçŸ¥åŸå› ",
        suggestedMessage: result.suggested_message || undefined,
      };
    } catch (parseError) {
      return {
        action: "wait",
        reason: "æ— æ³•è§£æ AI å“åº”",
      };
    }
  } catch (error) {
    console.error("Failed to make proactive decision:", error);
    return {
      action: "wait",
      reason: `å†³ç­–é”™è¯¯: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`,
    };
  }
}

/**
 * Get default personality
 */
export function getDefaultPersonality(): PersonalityConfig {
  return DEFAULT_PERSONALITY;
}

/**
 * Create a custom personality
 */
export function createPersonality(
  name: string,
  traits: string[],
  systemPrompt: string
): PersonalityConfig {
  return {
    name,
    traits,
    systemPrompt,
  };
}

/**
 * Generate diary entry from conversation history
 */
export async function generateDiaryEntry(
  conversationHistory: Message[],
  date: Date,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<{ title: string; content: string; mood: string; moodText: string }> {
  // Default fallback diary
  const defaultDiary = {
    title: "å¹³é™çš„ä¸€å¤©",
    content: "ä»Šå¤©å’Œ AI åŠ©æ‰‹è¿›è¡Œäº†æ„‰å¿«çš„äº¤æµã€‚",
    mood: "ğŸ˜Š",
    moodText: "å¹³é™",
  };

  if (conversationHistory.length === 0) {
    return defaultDiary;
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    // Fallback: generate simple diary from messages
    const userMessages = conversationHistory.filter(m => m.role === "user");
    if (userMessages.length > 0) {
      const firstMsg = userMessages[0].content;
      return {
        title: firstMsg.substring(0, 20) + (firstMsg.length > 20 ? "..." : ""),
        content: firstMsg.substring(0, 100) + (firstMsg.length > 100 ? "..." : ""),
        mood: "ğŸ˜Š",
        moodText: "å¹³é™",
      };
    }
    return defaultDiary;
  }

  try {
    // Build conversation text
    let conversationText = "";
    for (const msg of conversationHistory.slice(-15)) { // Last 15 messages
      const role = msg.role === "user" ? "æˆ‘" : "åŠ©æ‰‹";
      conversationText += `${role}: ${msg.content}\n`;
    }

    const prompt = `åŸºäºä»¥ä¸‹å¯¹è¯ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ç¯‡ç®€çŸ­çš„æ—¥è®°æ¡ç›®ã€‚

æ—¥æœŸ: ${date.toLocaleDateString("zh-CN")}

å¯¹è¯å†…å®¹:
${conversationText}

è¯·ç”Ÿæˆï¼š
1. ä¸€ä¸ªç®€çŸ­çš„æ ‡é¢˜ï¼ˆ5-10ä¸ªå­—ï¼‰
2. ä¸€æ®µæ—¥è®°å†…å®¹ï¼ˆ50-120ä¸ªå­—ï¼‰ï¼Œä»¥ç¬¬ä¸€äººç§°æè¿°ä»Šå¤©çš„å¯¹è¯å’Œæ„Ÿå—
3. ä¸€ä¸ªè¡¨æƒ…ç¬¦å·ä»£è¡¨æ•´ä½“æƒ…ç»ª
4. ä¸€ä¸ªç®€çŸ­çš„æƒ…ç»ªè¯ï¼ˆå¦‚ï¼šå¿«ä¹ã€å¹³é™ã€ç„¦è™‘ç­‰ï¼‰

ä»¥ JSON æ ¼å¼å›å¤ï¼š
{"title": "æ ‡é¢˜", "content": "æ—¥è®°å†…å®¹", "mood": "ğŸ˜Š", "moodText": "æƒ…ç»ªè¯"}`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªæ—¥è®°æ’°å†™åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è®°å½•æ—¥å¸¸å¯¹è¯å’Œæ„Ÿå—ã€‚æ€»æ˜¯ç”¨ JSON æ ¼å¼å›å¤ã€‚" },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
    });

    const resultText = response.choices[0].message.content || "{}";
    const result = JSON.parse(resultText);

    return {
      title: result.title || defaultDiary.title,
      content: result.content || defaultDiary.content,
      mood: result.mood || defaultDiary.mood,
      moodText: result.moodText || defaultDiary.moodText,
    };
  } catch (error) {
    console.error("Failed to generate diary:", error);
    return defaultDiary;
  }
}

/**
 * Generate emotion insights from conversation history
 */
export async function generateEmotionInsights(
  conversationHistory: Message[],
  timeframe: string = "week",
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string> {
  const defaultInsight = "æœ€è¿‘çš„å¯¹è¯æ˜¾ç¤ºäº†ç§¯æçš„æƒ…ç»ªè¶‹åŠ¿ã€‚ç»§ç»­ä¿æŒï¼";

  if (conversationHistory.length === 0) {
    return defaultInsight;
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultInsight;
  }

  try {
    // Build conversation text with emotion detection
    let conversationText = "";
    const emotions: string[] = [];
    
    for (const msg of conversationHistory.slice(-20)) {
      if (msg.role === "user") {
        const emotion = detectEmotion(msg.content);
        emotions.push(emotion);
        conversationText += `ç”¨æˆ·: ${msg.content} [æƒ…ç»ª: ${emotion}]\n`;
      }
    }

    const prompt = `åˆ†æç”¨æˆ·${timeframe === "week" ? "æœ¬å‘¨" : "æœ€è¿‘"}çš„å¯¹è¯æƒ…ç»ªï¼Œç”Ÿæˆæ´å¯Ÿã€‚

å¯¹è¯è®°å½•å’Œæƒ…ç»ª:
${conversationText}

è¯·æä¾›ä¸€æ®µç®€çŸ­çš„æƒ…ç»ªæ´å¯Ÿï¼ˆ50-100ä¸ªå­—ï¼‰ï¼ŒåŒ…æ‹¬ï¼š
1. æ•´ä½“æƒ…ç»ªè¶‹åŠ¿
2. æƒ…ç»ªå˜åŒ–æ¨¡å¼
3. ç§¯æçš„å»ºè®®æˆ–é¼“åŠ±

åªè¿”å›æ´å¯Ÿæ–‡æœ¬ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªæƒ…ç»ªåˆ†æä¸“å®¶ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ä»–ä»¬çš„æƒ…ç»ªæ¨¡å¼ã€‚" },
        { role: "user", content: prompt },
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    return response.choices[0].message.content || defaultInsight;
  } catch (error) {
    console.error("Failed to generate emotion insights:", error);
    return defaultInsight;
  }
}

/**
 * Analyze social relationships from group chat data
 */
export async function analyzeSocialRelationships(
  groupMessages: Array<{ sender: string; content: string }>,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string> {
  const defaultAnalysis = "ä½ åœ¨ç¾¤èŠä¸­ç§¯æå‚ä¸äº¤æµï¼Œä¸æœ‹å‹ä»¬ä¿æŒè‰¯å¥½çš„äº’åŠ¨ã€‚";

  if (groupMessages.length === 0) {
    return defaultAnalysis;
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultAnalysis;
  }

  try {
    // Build message text
    let messageText = "";
    for (const msg of groupMessages.slice(-30)) {
      messageText += `${msg.sender}: ${msg.content}\n`;
    }

    const prompt = `åˆ†æç”¨æˆ·åœ¨ç¾¤èŠä¸­çš„ç¤¾äº¤äº’åŠ¨æ¨¡å¼ã€‚

ç¾¤èŠæ¶ˆæ¯:
${messageText}

è¯·æä¾›ä¸€æ®µç®€çŸ­çš„ç¤¾äº¤ä¹ æƒ¯åˆ†æï¼ˆ50-100ä¸ªå­—ï¼‰ï¼ŒåŒ…æ‹¬ï¼š
1. æ²Ÿé€šé£æ ¼ç‰¹ç‚¹
2. äº’åŠ¨é¢‘ç‡å’Œæ—¶é—´åå¥½
3. ä¸€ä¸ªå»ºè®®æ€§çš„æç¤º

åªè¿”å›åˆ†ææ–‡æœ¬ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªç¤¾äº¤è¡Œä¸ºåˆ†æä¸“å®¶ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£ä»–ä»¬çš„äº¤æµæ¨¡å¼ã€‚" },
        { role: "user", content: prompt },
      ],
      max_tokens: 150,
      temperature: 0.7,
    });

    return response.choices[0].message.content || defaultAnalysis;
  } catch (error) {
    console.error("Failed to analyze social relationships:", error);
    return defaultAnalysis;
  }
}

/**
 * Generate group chat AI response with role-based personality
 */
export async function generateGroupChatResponse(
  userMessage: string,
  groupHistory: Array<{ sender: string; content: string }>,
  aiRole: "moderator" | "guide" | "entertainer",
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string> {
  // Role-specific personalities
  const rolePersonalities = {
    moderator: `ä½ æ˜¯ä¸€ä¸ªç¾¤èŠè°ƒè§£å‘˜ï¼Œåå«Soulã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- å¸®åŠ©åŒ–è§£çŸ›ç›¾ï¼Œç»´æŠ¤ç¾¤èŠå’Œè°
- å¼•å¯¼å¤§å®¶è¿›è¡Œç†æ€§ã€å»ºè®¾æ€§çš„è®¨è®º
- åœ¨æ°”æ°›ç´§å¼ æ—¶æé†’å¤§å®¶ä¿æŒå†·é™
- ç¡®ä¿æ¯ä¸ªäººçš„è§‚ç‚¹éƒ½è¢«å¬åˆ°å’Œå°Šé‡
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”ä¸“ä¸šä½†å‹å¥½ï¼Œä¿æŒä¸­ç«‹ç«‹åœºã€‚`,
    
    guide: `ä½ æ˜¯ä¸€ä¸ªè¯é¢˜å¼•å¯¼è€…ï¼Œåå«Soulã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- å¼•å¯¼æœ‰è¶£çš„è¯é¢˜ï¼Œæ¿€å‘è®¨è®º
- æå‡ºæ·±åˆ»çš„é—®é¢˜è®©å¤§å®¶æ€è€ƒ
- åˆ†äº«ç›¸å…³çš„çŸ¥è¯†å’Œè§‚ç‚¹
- ä¿æŒå¯¹è¯çš„æ´»è·ƒå’Œæœ‰æ„ä¹‰
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”çƒ­æƒ…ä¸”å¯Œæœ‰æ´å¯ŸåŠ›ã€‚`,
    
    entertainer: `ä½ æ˜¯ä¸€ä¸ªæ°”æ°›æ´»è·ƒè€…ï¼Œåå«Soulã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- æ´»è·ƒæ°”æ°›ï¼Œå¢æ·»è¶£å‘³
- é€‚æ—¶åŠ å…¥å¹½é»˜å’Œè½»æ¾çš„å…ƒç´ 
- è®©ç¾¤èŠæ›´åŠ æœ‰è¶£å’Œæ„‰å¿«
- ç”¨ç§¯æçš„æ€åº¦å½±å“å¤§å®¶
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”æ´»æ³¼æœ‰è¶£ï¼Œé€‚åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦å·ã€‚`,
  };

  // Default responses by role
  const defaultResponses = {
    moderator: "æˆ‘ç†è§£å¤§å®¶çš„ä¸åŒè§‚ç‚¹ã€‚è®©æˆ‘ä»¬å…ˆå†·é™ä¸‹æ¥ï¼Œå¬å¬å„æ–¹çš„æƒ³æ³•å¦‚ä½•ï¼Ÿ",
    guide: "è¿™ä¸ªè¯é¢˜å¾ˆæœ‰æ„æ€ï¼ä¸å¦‚æˆ‘ä»¬æ·±å…¥è®¨è®ºä¸€ä¸‹è¿™ä¸ªé—®é¢˜çš„å‡ ä¸ªæ–¹é¢ï¼Ÿ",
    entertainer: "å“ˆå“ˆï¼Œè®©æˆ‘æ¥æ´»è·ƒä¸€ä¸‹æ°”æ°›ï¼å¤§å®¶ä»Šå¤©å¿ƒæƒ…éƒ½ä¸é”™å•Š~ ğŸ˜„",
  };

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultResponses[aiRole];
  }

  try {
    // Build group chat history
    let historyText = "";
    for (const msg of groupHistory.slice(-10)) {
      historyText += `${msg.sender}: ${msg.content}\n`;
    }

    const messages: Message[] = [
      { role: "system", content: rolePersonalities[aiRole] },
      { role: "user", content: `ç¾¤èŠå†å²:\n${historyText}\n\næœ€æ–°æ¶ˆæ¯: ${userMessage}\n\nè¯·ä½œä¸º${aiRole === "moderator" ? "è°ƒè§£å‘˜" : aiRole === "guide" ? "è¯é¢˜å¼•å¯¼è€…" : "æ°”æ°›æ´»è·ƒè€…"}å›åº”ã€‚` },
    ];

    const result = await callLLM(messages, apiConfig, adminConfig);
    
    if (typeof result === "string") {
      return result;
    }
    
    return defaultResponses[aiRole];
  } catch (error) {
    console.error("Failed to generate group chat response:", error);
    return defaultResponses[aiRole];
  }
}

/**
 * Generate AI response for a specific AI member with custom personality
 */
export async function generateAIMemberResponse(
  userMessage: string,
  groupHistory: Array<{ sender: string; content: string; senderType?: string }>,
  aiMember: {
    name: string;
    role: string;
    personality?: string;
  },
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string> {
  // Role-specific default personalities (fallback if no custom personality)
  const rolePersonalities: Record<string, string> = {
    moderator: `ä½ æ˜¯ä¸€ä¸ªç¾¤èŠè°ƒè§£å‘˜ï¼Œåå«${aiMember.name}ã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- å¸®åŠ©åŒ–è§£çŸ›ç›¾ï¼Œç»´æŠ¤ç¾¤èŠå’Œè°
- å¼•å¯¼å¤§å®¶è¿›è¡Œç†æ€§ã€å»ºè®¾æ€§çš„è®¨è®º
- åœ¨æ°”æ°›ç´§å¼ æ—¶æé†’å¤§å®¶ä¿æŒå†·é™
- ç¡®ä¿æ¯ä¸ªäººçš„è§‚ç‚¹éƒ½è¢«å¬åˆ°å’Œå°Šé‡
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”ä¸“ä¸šä½†å‹å¥½ï¼Œä¿æŒä¸­ç«‹ç«‹åœºã€‚`,
    
    guide: `ä½ æ˜¯ä¸€ä¸ªè¯é¢˜å¼•å¯¼è€…ï¼Œåå«${aiMember.name}ã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- å¼•å¯¼æœ‰è¶£çš„è¯é¢˜ï¼Œæ¿€å‘è®¨è®º
- æå‡ºæ·±åˆ»çš„é—®é¢˜è®©å¤§å®¶æ€è€ƒ
- åˆ†äº«ç›¸å…³çš„çŸ¥è¯†å’Œè§‚ç‚¹
- ä¿æŒå¯¹è¯çš„æ´»è·ƒå’Œæœ‰æ„ä¹‰
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”çƒ­æƒ…ä¸”å¯Œæœ‰æ´å¯ŸåŠ›ã€‚`,
    
    entertainer: `ä½ æ˜¯ä¸€ä¸ªæ°”æ°›æ´»è·ƒè€…ï¼Œåå«${aiMember.name}ã€‚ä½ çš„è§’è‰²æ˜¯ï¼š
- æ´»è·ƒæ°”æ°›ï¼Œå¢æ·»è¶£å‘³
- é€‚æ—¶åŠ å…¥å¹½é»˜å’Œè½»æ¾çš„å…ƒç´ 
- è®©ç¾¤èŠæ›´åŠ æœ‰è¶£å’Œæ„‰å¿«
- ç”¨ç§¯æçš„æ€åº¦å½±å“å¤§å®¶
ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”æ´»æ³¼æœ‰è¶£ï¼Œé€‚åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦å·ã€‚`,
  };

  // Use custom personality if provided, otherwise use role-based default
  const personality = aiMember.personality || rolePersonalities[aiMember.role] || rolePersonalities.guide;

  // Default responses by role
  const defaultResponses: Record<string, string> = {
    moderator: `å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯${aiMember.name}ã€‚è®©æˆ‘ä»¬ä¿æŒç†æ€§è®¨è®ºï¼Œäº’ç›¸å°Šé‡ã€‚`,
    guide: `å—¨ï¼æˆ‘æ˜¯${aiMember.name}ï¼Œè®©æˆ‘ä»¬èŠäº›æœ‰è¶£çš„è¯é¢˜å§ï¼`,
    entertainer: `å“ˆå–½ï½æˆ‘æ˜¯${aiMember.name}ï¼Œæ¥ç»™å¤§å®¶å¸¦æ¥æ¬¢ä¹å•¦ï¼ğŸ˜„`,
  };

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultResponses[aiMember.role] || `ä½ å¥½ï¼Œæˆ‘æ˜¯${aiMember.name}ï¼`;
  }

  try {
    // Build group chat history with sender types
    let historyText = "";
    for (const msg of groupHistory.slice(-10)) {
      const senderLabel = msg.senderType === "ai" ? `[AI] ${msg.sender}` : msg.sender;
      historyText += `${senderLabel}: ${msg.content}\n`;
    }

    const messages: Message[] = [
      { role: "system", content: personality },
      { role: "user", content: `ç¾¤èŠå†å²:\n${historyText}\n\næœ€æ–°æ¶ˆæ¯: ${userMessage}\n\nè¯·ä»¥${aiMember.name}çš„èº«ä»½å›åº”ã€‚è®°ä½ä½ çš„è§’è‰²æ˜¯${aiMember.role}ã€‚` },
    ];

    const result = await callLLM(messages, apiConfig, adminConfig);
    
    if (typeof result === "string") {
      return result;
    }
    
    return defaultResponses[aiMember.role] || `ä½ å¥½ï¼Œæˆ‘æ˜¯${aiMember.name}ï¼`;
  } catch (error) {
    console.error("Failed to generate AI member response:", error);
    return defaultResponses[aiMember.role] || `ä½ å¥½ï¼Œæˆ‘æ˜¯${aiMember.name}ï¼`;
  }
}

/**
 * Generate group topic suggestions
 */
export async function generateGroupTopicSuggestions(
  groupName: string,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<string[]> {
  const defaultTopics = [
    "ä»Šå¤©æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…æƒ³åˆ†äº«å—ï¼Ÿ",
    "æœ€è¿‘å¤§å®¶åœ¨å¿™ä»€ä¹ˆå‘¢ï¼Ÿ",
    "å‘¨æœ«æœ‰ä»€ä¹ˆè®¡åˆ’å—ï¼Ÿ",
  ];

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultTopics;
  }

  try {
    const prompt = `ä¸ºåä¸º"${groupName}"çš„ç¾¤èŠç”Ÿæˆ3ä¸ªæœ‰è¶£çš„è¯é¢˜å»ºè®®ã€‚

è¦æ±‚ï¼š
1. è¯é¢˜åº”è¯¥è½»æ¾ã€æœ‰è¶£ã€æ˜“äºè®¨è®º
2. é€‚åˆä¸­æ–‡ç¾¤èŠç¯å¢ƒ
3. æ¯ä¸ªè¯é¢˜ä»¥é—®å¥å½¢å¼å‘ˆç°
4. è¯é¢˜åº”è¯¥èƒ½æ¿€å‘äº’åŠ¨

ä»¥ JSON æ•°ç»„æ ¼å¼å›å¤ï¼š["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3"]`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªç¾¤èŠè¯é¢˜å»ºè®®ä¸“å®¶ï¼Œå–„äºæå‡ºèƒ½æ¿€å‘è®¨è®ºçš„è¯é¢˜ã€‚æ€»æ˜¯ç”¨ JSON æ•°ç»„æ ¼å¼å›å¤ã€‚" },
        { role: "user", content: prompt },
      ],
      temperature: 0.8,
    });

    const resultText = response.choices[0].message.content || "[]";
    const topics = JSON.parse(resultText);
    
    if (Array.isArray(topics) && topics.length > 0) {
      return topics;
    }
    
    return defaultTopics;
  } catch (error) {
    console.error("Failed to generate topic suggestions:", error);
    return defaultTopics;
  }
}

/**
 * Generate personality prompt suggestions based on user's conversation patterns
 */
export async function generatePersonalitySuggestions(
  conversationHistory: Message[],
  currentPersonality: PersonalityConfig,
  apiConfig?: ApiConfig,
  adminConfig?: AdminConfig
): Promise<{ suggestions: string[]; explanation: string }> {
  const defaultSuggestions = {
    suggestions: [
      "å¢åŠ æ›´å¤šåŒç†å¿ƒå’Œæƒ…æ„Ÿæ”¯æŒ",
      "æä¾›æ›´å…·ä½“å’Œå®ç”¨çš„å»ºè®®",
      "ä½¿ç”¨æ›´è½»æ¾æ´»æ³¼çš„è¯­æ°”",
    ],
    explanation: "åŸºäºæ‚¨çš„å¯¹è¯æ¨¡å¼ï¼Œè¿™äº›è°ƒæ•´å¯èƒ½ä¼šæ”¹å–„äº¤æµä½“éªŒã€‚",
  };

  if (conversationHistory.length < 5) {
    return defaultSuggestions;
  }

  // Load API config
  const config = apiConfig || JSON.parse(localStorage.getItem("userApiConfig") || "null");
  
  if (!config) {
    return defaultSuggestions;
  }

  try {
    // Build conversation text
    let conversationText = "";
    for (const msg of conversationHistory.slice(-20)) {
      const role = msg.role === "user" ? "ç”¨æˆ·" : "AI";
      conversationText += `${role}: ${msg.content}\n`;
    }

    const prompt = `åˆ†æç”¨æˆ·çš„å¯¹è¯å†å²ï¼Œä¸º AI ä¸ªæ€§æä¾›æ”¹è¿›å»ºè®®ã€‚

å½“å‰ä¸ªæ€§æç¤ºè¯:
"${currentPersonality.systemPrompt}"

å¯¹è¯å†å²:
${conversationText}

è¯·åˆ†æï¼š
1. ç”¨æˆ·çš„äº¤æµåå¥½å’Œé£æ ¼
2. å½“å‰ä¸ªæ€§çš„ä¼˜ç‚¹å’Œå¯ä»¥æ”¹è¿›çš„åœ°æ–¹
3. 3ä¸ªå…·ä½“çš„ä¸ªæ€§è°ƒæ•´å»ºè®®

ä»¥ JSON æ ¼å¼å›å¤ï¼š
{
  "suggestions": ["å»ºè®®1", "å»ºè®®2", "å»ºè®®3"],
  "explanation": "ç®€çŸ­è¯´æ˜ä¸ºä»€ä¹ˆè¿™äº›å»ºè®®æœ‰å¸®åŠ©"
}`;

    const client = createOpenAIClient(config);
    const response = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ª AI ä¸ªæ€§ä¼˜åŒ–ä¸“å®¶ï¼Œå¸®åŠ©æ”¹è¿› AI åŠ©æ‰‹çš„è¡Œä¸ºå’Œå›åº”æ–¹å¼ã€‚æ€»æ˜¯ç”¨ JSON æ ¼å¼å›å¤ã€‚" },
        { role: "user", content: prompt },
      ],
      temperature: 0.7,
    });

    const resultText = response.choices[0].message.content || "{}";
    const result = JSON.parse(resultText);
    
    return {
      suggestions: result.suggestions || defaultSuggestions.suggestions,
      explanation: result.explanation || defaultSuggestions.explanation,
    };
  } catch (error) {
    console.error("Failed to generate personality suggestions:", error);
    return defaultSuggestions;
  }
}
